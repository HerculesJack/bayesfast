{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayesfast as bf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 16 # number of dims\n",
    "a = 1.\n",
    "b = 0.5\n",
    "lower = np.full(D, -30.) # lower bound of the prior for x_1, ...\n",
    "upper = np.full(D, 30.) # upper bound of the prior for x_1, ...\n",
    "lower[0] = -4 # lower bound of the prior for x_0\n",
    "upper[0] = 4 # upper bound of the prior for x_0\n",
    "bound = np.array((lower, upper)).T\n",
    "diff = bound[:, 1] - bound[:, 0]\n",
    "const = np.sum(np.log(diff)) # normalization of the flat prior\n",
    "\n",
    "def logp(x):\n",
    "    n = x.shape[-1]\n",
    "    _a = -0.5 * x[..., 0]**2 / a**2\n",
    "    _b = -0.5 * np.sum(x[..., 1:]**2, axis=-1) * np.exp(-2 * b * x[..., 0])\n",
    "    _c = (-0.5 * np.log(2 * np.pi * a**2) - \n",
    "          0.5 * (n - 1) * np.log(2 * np.pi) - (n - 1) * b * x[..., 0])\n",
    "    return _a + _b + _c - const\n",
    "\n",
    "def grad(x):\n",
    "    n = x.shape[-1]\n",
    "    foo = -x / np.insert(np.full((*x.shape[:-1], n - 1), \n",
    "                                 np.exp(2 * b * x[..., 0])), 0, a**2, axis=-1)\n",
    "    foo[0] += b * np.sum(x[..., 1:]**2, axis=-1) * np.exp(-2 * b * x[..., 0])\n",
    "    foo[0] -= (n - 1) * b\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33213</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>126.70 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33213' processes=8 threads=8, memory=126.70 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "den = bf.DensityLite(logp=logp, grad=grad, input_size=D, input_scales=bound,\n",
    "                     hard_bounds=True)\n",
    "sample_trace = {'n_chain': 8, 'n_iter': 2500, 'n_warmup': 1000}\n",
    "rec = bf.Recipe(density=den, sample={'sample_trace': sample_trace,\n",
    "                'random_state': 0}, post={}, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #7 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #7 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #7 : overflow encountered in exp\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #3 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #3 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #2 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #2 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #6 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #6 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #1 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #1 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #5 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #5 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #6 : invalid value encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #4 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #4 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #0 : divide by zero encountered in log\n",
      "  warnings.warn(msg[1], msg[0])\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/sample.py:104: RuntimeWarning:  CHAIN #0 : divide by zero encountered in true_divide\n",
      "  warnings.warn(msg[1], msg[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHAIN #2 : sampling proceeding [ 500 / 2500 ], last 500 samples used 1.78 seconds. (warmup)\n",
      " CHAIN #1 : sampling proceeding [ 500 / 2500 ], last 500 samples used 1.77 seconds. (warmup)\n",
      " CHAIN #3 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.29 seconds. (warmup)\n",
      " CHAIN #5 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.05 seconds. (warmup)\n",
      " CHAIN #4 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.01 seconds. (warmup)\n",
      " CHAIN #7 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.51 seconds. (warmup)\n",
      " CHAIN #0 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.18 seconds. (warmup)\n",
      " CHAIN #6 : sampling proceeding [ 500 / 2500 ], last 500 samples used 2.46 seconds. (warmup)\n",
      " CHAIN #1 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 1.70 seconds. (warmup)\n",
      " CHAIN #2 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 1.95 seconds. (warmup)\n",
      " CHAIN #3 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.03 seconds. (warmup)\n",
      " CHAIN #4 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.01 seconds. (warmup)\n",
      " CHAIN #5 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.21 seconds. (warmup)\n",
      " CHAIN #0 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.11 seconds. (warmup)\n",
      " CHAIN #7 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.30 seconds. (warmup)\n",
      " CHAIN #6 : sampling proceeding [ 1000 / 2500 ], last 500 samples used 2.28 seconds. (warmup)\n",
      " CHAIN #2 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 2.05 seconds.\n",
      " CHAIN #1 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 2.24 seconds.\n",
      " CHAIN #3 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 1.93 seconds.\n",
      " CHAIN #5 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 1.96 seconds.\n",
      " CHAIN #7 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 1.87 seconds.\n",
      " CHAIN #4 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 2.21 seconds.\n",
      " CHAIN #0 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 2.03 seconds.\n",
      " CHAIN #6 : sampling proceeding [ 1500 / 2500 ], last 500 samples used 2.76 seconds.\n",
      " CHAIN #1 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.13 seconds.\n",
      " CHAIN #2 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.31 seconds.\n",
      " CHAIN #3 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.21 seconds.\n",
      " CHAIN #5 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.00 seconds.\n",
      " CHAIN #7 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.07 seconds.\n",
      " CHAIN #0 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.30 seconds.\n",
      " CHAIN #4 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.38 seconds.\n",
      " CHAIN #6 : sampling proceeding [ 2000 / 2500 ], last 500 samples used 2.09 seconds.\n",
      " CHAIN #3 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.40 seconds.\n",
      " CHAIN #2 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.25 seconds.\n",
      " CHAIN #5 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.15 seconds.\n",
      " CHAIN #1 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.15 seconds.\n",
      " CHAIN #7 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.89 seconds.\n",
      " CHAIN #4 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 10.82 seconds.\n",
      " CHAIN #0 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 11.16 seconds.\n",
      " CHAIN #6 : sampling finished [ 2500 / 2500 ], obtained 2500 samples in 11.62 seconds.\n",
      "\n",
      " *** SampleStep proceeding: iter #0 finished. *** \n",
      "\n",
      " ***** SampleStep finished. ***** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/homes/h/hejia/.conda/envs/hejia@cori-2/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/global/u2/h/hejia/bayesfast/bayesfast/core/density.py:959: RuntimeWarning: use_surrogate will be ignored for DensityLite.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***** PostStep finished. ***** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-63.49564469101636, 0.01605608763046655)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.get().logz, rec.get().logz_err # fiducial value: logz = -63.4988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hejia@cori-2",
   "language": "python",
   "name": "hejia-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
